{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "import io\n",
    "import requests\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_parlement = \"https://www.lachambre.be/FLWB/PDF/55/3197/55K3197001.pdf\" \n",
    "doc2 = \"http://www.lachambre.be/FLWB/PDF/55/3509/55K3509001.pdf\"\n",
    "doc3 = \"http://www.lachambre.be/FLWB/PDF/55/2894/55K2894001.pdf\"\n",
    "doc4 = \"http://www.lachambre.be/FLWB/PDF/55/2092/55K2092001.pdf\"\n",
    "plenary_doc = \"\" # 3- Séances Plénières integral - Maciej\n",
    "com_integral = \"\" # 4- Commissions integral - Mourad\n",
    "bulletin = \"\" # 5- Bulletins des questions et réponses écrites - Ramina\n",
    "rapport = \"\" # 6- Rapports déposés en exécution d'une loi - Sarkis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(url):\n",
    "    rq = requests.get(url)\n",
    "    left_column_text_all_pages = \"\"\n",
    "    right_column_text_all_pages = \"\"\n",
    "\n",
    "    with pdfplumber.open(io.BytesIO(rq.content)) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            words = page.extract_words()\n",
    "            threshold_x = 300\n",
    "\n",
    "            left_column_words = [word for word in words if word['x0'] < threshold_x]\n",
    "            right_column_words = [word for word in words if word['x0'] >= threshold_x]\n",
    "\n",
    "            left_column_text = ' '.join([word['text'] for word in left_column_words])\n",
    "            right_column_text = ' '.join([word['text'] for word in right_column_words])\n",
    "\n",
    "            left_column_text_all_pages += left_column_text + ' '\n",
    "            right_column_text_all_pages += right_column_text + ' '\n",
    "\n",
    "            left_column_clean = re.sub(r'(?<=\\w)-(\\s)(?=\\w)', r'', left_column_text_all_pages) # remove end_line hyphens\n",
    "            left_column_clean = re.sub(r'DOC 55 \\d{4}/001', '', left_column_clean)\n",
    "            left_column_clean = re.sub(r'\\d{4}/001 DOC 55', '', left_column_clean)\n",
    "            left_column_clean = re.sub(r'CHAMBRE \\d+e SESSION DE LA 55e LÉGISLATURE \\d{4}(?: \\d+)?', '', left_column_clean)\n",
    "\n",
    "            right_column_clean = re.sub(r'(?<=\\w)-(\\s)(?=\\w)', r'', right_column_text_all_pages) # remove end_line hyphens\n",
    "            right_column_clean = re.sub(r'DOC 55 \\d{4}/001', '', right_column_clean)\n",
    "            right_column_clean = re.sub(r'\\d{4}/001 DOC 55', '', right_column_clean)\n",
    "            right_column_clean = re.sub(r'\\d{4} KAMER • \\d+e ZITTING VAN DE 55e ZITTINGSPERIODE(?: \\d+)?', '', right_column_clean)\n",
    "\n",
    "    return left_column_clean, right_column_clean\n",
    "\n",
    "    # {\"fr_pdf_text\" : left_column_text_all_pages, \"nl_pdf_text\": right_column_text_all_pages}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('apercu_complet.json')\n",
    "df_pdf_not_disponible = df[df[\"DocumentChambre\"].str.contains(\"pasdisponible\")]\n",
    "df_pdf_disponible = df[~df[\"DocumentChambre\"].str.contains(\"pasdisponible\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lh/rbpzcs3522qg45v9lc_xvgyc0000gn/T/ipykernel_16533/1449241180.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  first_300[['fr_text', 'nl_text']] = first_300['DocumentChambre'].apply(lambda url: pd.Series(get_text(url)))\n",
      "/var/folders/lh/rbpzcs3522qg45v9lc_xvgyc0000gn/T/ipykernel_16533/1449241180.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  first_300[['fr_text', 'nl_text']] = first_300['DocumentChambre'].apply(lambda url: pd.Series(get_text(url)))\n"
     ]
    }
   ],
   "source": [
    "first_300 = df_pdf_disponible.iloc[:300]\n",
    "first_300[['fr_text', 'nl_text']] = first_300['DocumentChambre'].apply(lambda url: pd.Series(get_text(url)))\n",
    "first_300.to_csv(\"first_300.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lh/rbpzcs3522qg45v9lc_xvgyc0000gn/T/ipykernel_16533/2062434630.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  second_300[['fr_text', 'nl_text']] = second_300['DocumentChambre'].apply(lambda url: pd.Series(get_text(url)))\n",
      "/var/folders/lh/rbpzcs3522qg45v9lc_xvgyc0000gn/T/ipykernel_16533/2062434630.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  second_300[['fr_text', 'nl_text']] = second_300['DocumentChambre'].apply(lambda url: pd.Series(get_text(url)))\n"
     ]
    }
   ],
   "source": [
    "second_300 = df_pdf_disponible.iloc[301:600]\n",
    "second_300[['fr_text', 'nl_text']] = second_300['DocumentChambre'].apply(lambda url: pd.Series(get_text(url)))\n",
    "second_300.to_csv(\"second_300.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lh/rbpzcs3522qg45v9lc_xvgyc0000gn/T/ipykernel_16533/2130033794.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from_600_1300[['fr_text', 'nl_text']] = from_600_1300['DocumentChambre'].apply(lambda url: pd.Series(get_text(url)))\n",
      "/var/folders/lh/rbpzcs3522qg45v9lc_xvgyc0000gn/T/ipykernel_16533/2130033794.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from_600_1300[['fr_text', 'nl_text']] = from_600_1300['DocumentChambre'].apply(lambda url: pd.Series(get_text(url)))\n"
     ]
    }
   ],
   "source": [
    "from_600_1300 = df_pdf_disponible.iloc[601:1300]\n",
    "from_600_1300[['fr_text', 'nl_text']] = from_600_1300['DocumentChambre'].apply(lambda url: pd.Series(get_text(url)))\n",
    "from_600_1300.to_csv(\"from_600_1300.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lh/rbpzcs3522qg45v9lc_xvgyc0000gn/T/ipykernel_16533/1940002320.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from_1300_end[['fr_text', 'nl_text']] = from_1300_end['DocumentChambre'].apply(lambda url: pd.Series(get_text(url)))\n",
      "/var/folders/lh/rbpzcs3522qg45v9lc_xvgyc0000gn/T/ipykernel_16533/1940002320.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from_1300_end[['fr_text', 'nl_text']] = from_1300_end['DocumentChambre'].apply(lambda url: pd.Series(get_text(url)))\n"
     ]
    }
   ],
   "source": [
    "from_1300_end = df_pdf_disponible.iloc[1301:]\n",
    "from_1300_end[['fr_text', 'nl_text']] = from_1300_end['DocumentChambre'].apply(lambda url: pd.Series(get_text(url)))\n",
    "from_1300_end.to_csv(\"from_1300_end.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lh/rbpzcs3522qg45v9lc_xvgyc0000gn/T/ipykernel_16533/4224887151.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pdf_not_disponible[\"fr_text\"] = \"PDF not disponible\"\n",
      "/var/folders/lh/rbpzcs3522qg45v9lc_xvgyc0000gn/T/ipykernel_16533/4224887151.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pdf_not_disponible[\"nl_text\"] = \"PDF not disponible\"\n"
     ]
    }
   ],
   "source": [
    "df_pdf_not_disponible[\"fr_text\"] = \"PDF not disponible\"\n",
    "df_pdf_not_disponible[\"nl_text\"] = \"PDF not disponible\"\n",
    "df_pdf_not_disponible.to_csv(\"pdf_not_disponible.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1300_end = pd.read_csv(\"./folder_to_ignore/processed_csv/from_1300_end.csv\")\n",
    "from2800_end = df1300_end.iloc[1500:]\n",
    "from2800_end.to_csv(\"./processed_csv/from2800_end.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pdf_disponible[['fr_text', 'nl_text']] = df_pdf_disponible['DocumentChambre'].apply(lambda url: pd.Series(get_text(url)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_url(url):\n",
    "#     left_text, right_text = get_text(url)\n",
    "#     return (left_text, right_text)\n",
    "\n",
    "# # Process URLs using ThreadPoolExecutor\n",
    "# with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "#     results = list(executor.map(process_url, df_pdf_disponible['DocumentChambre']))\n",
    "\n",
    "# # Unpack the results and add them as new columns to the DataFrame\n",
    "# df_pdf_disponible[['left_column_clean', 'right_column_clean']] = pd.DataFrame(results, columns=['left', 'right'])\n",
    "\n",
    "# # Display the updated DataFrame\n",
    "# print(df_pdf_disponible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pdf_not_disponible[\"fr_text\"] = \"PDF not disponible\"\n",
    "# df_pdf_not_disponible[\"nl_text\"] = \"PDF not disponible\"\n",
    "# df_pdf_disponible[\"fr_text\"] = df_pdf_disponible[\"DocumentChambre\"].map(lambda x: get_text(x)[0])\n",
    "# df_pdf_disponible[\"nl_text\"] = df_pdf_disponible[\"DocumentChambre\"].map(lambda x: get_text(x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json('apercu_complet.json')\n",
    "\n",
    "# def add_text_to_df(df):\n",
    "#     df_pdf_not_disponible = df[df[\"DocumentChambre\"].str.contains(\"pasdisponible\")]\n",
    "#     df_pdf_disponible = df[~df[\"DocumentChambre\"].str.contains(\"pasdisponible\")]\n",
    "#     df_pdf_disponible[\"fr_text\"] = df_pdf_disponible[\"DocumentChambre\"].map(lambda x: get_text(x)[0])\n",
    "#     df_pdf_disponible[\"nl_text\"] = df_pdf_disponible[\"DocumentChambre\"].map(lambda x: get_text(x)[1])\n",
    "#     df_pdf_not_disponible[\"fr_text\"] = \"PDF not disponible\"\n",
    "#     df_pdf_not_disponible[\"nl_text\"] = \"PDF not disponible\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def new_get_text(df):\n",
    "#     try:\n",
    "#         rq = requests.get(df[\"DocumentChambre\"])\n",
    "#         left_column_text_all_pages = \"\"\n",
    "#         right_column_text_all_pages = \"\"\n",
    "\n",
    "#         with pdfplumber.open(io.BytesIO(rq.content)) as pdf:\n",
    "#             for page in pdf.pages:\n",
    "#                 words = page.extract_words()\n",
    "#                 threshold_x = 300\n",
    "\n",
    "#                 left_column_words = [word for word in words if word['x0'] < threshold_x]\n",
    "#                 right_column_words = [word for word in words if word['x0'] >= threshold_x]\n",
    "\n",
    "#                 left_column_text = ' '.join([word['text'] for word in left_column_words])\n",
    "#                 right_column_text = ' '.join([word['text'] for word in right_column_words])\n",
    "\n",
    "#                 left_column_text_all_pages += left_column_text + ' '\n",
    "#                 right_column_text_all_pages += right_column_text + ' '\n",
    "\n",
    "#                 left_column_clean = re.sub(r'(?<=\\w)-(\\s)(?=\\w)', r'', left_column_text_all_pages) # remove end_line hyphens\n",
    "#                 left_column_clean = re.sub(r'DOC 55 \\d{4}/001', '', left_column_clean)\n",
    "#                 left_column_clean = re.sub(r'\\d{4}/001 DOC 55', '', left_column_clean)\n",
    "#                 left_column_clean = re.sub(r'CHAMBRE \\d+e SESSION DE LA 55e LÉGISLATURE \\d{4}(?: \\d+)?', '', left_column_clean)\n",
    "\n",
    "#                 right_column_clean = re.sub(r'(?<=\\w)-(\\s)(?=\\w)', r'', right_column_text_all_pages) # remove end_line hyphens\n",
    "#                 right_column_clean = re.sub(r'DOC 55 \\d{4}/001', '', right_column_clean)\n",
    "#                 right_column_clean = re.sub(r'\\d{4}/001 DOC 55', '', right_column_clean)\n",
    "#                 right_column_clean = re.sub(r'\\d{4} KAMER • \\d+e ZITTING VAN DE 55e ZITTINGSPERIODE(?: \\d+)?', '', right_column_clean)\n",
    "\n",
    "#         df[\"fr_text\"] = left_column_clean\n",
    "#         df[\"nl_text\"] = right_column_clean\n",
    "#         return df\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(type(e))\n",
    "#         return e\n",
    "\n",
    "# for i in df_pdf_disponible.loc(): \n",
    "#     print(i)\n",
    "#     # new_get_text(i)\n",
    "\n",
    "# # search_links = get_search_url_list(end_page=334)\n",
    "\n",
    "# # urls = list(itertools.chain.from_iterable(thread_map(get_urls_from_search_page, search_links)))\n",
    "\n",
    "# # with requests.Session() as session:\n",
    "#     # new_df = df for df in thread_map(partial(new_get_text, session=session), df_pdf_disponible)\n",
    "\n",
    "# # properties.to_csv(\"properties.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
