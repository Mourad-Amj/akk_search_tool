{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = \"https://www.lachambre.be/doc/CCRI/html/55/ic1163x.html\"\n",
    "\n",
    "\n",
    "main_response = requests.get(main_url)\n",
    "soup = bs(main_response.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ NEW QUESTION ------FROM Hervé Rigot\n",
      "Adding paragraph...\n",
      "------------------\n",
      "Found 1 questions Hervé Rigot\n",
      "------ NEW QUESTION ------FROM Hervé Rigot\n",
      "Adding paragraph...\n",
      "------------------\n",
      "Found 1 questions Hervé Rigot\n",
      "------ NEW QUESTION ------FROM Malik Ben Achour\n",
      "Adding paragraph...\n",
      "------------------\n",
      "Found 2 questions Malik Ben Achour\n",
      "------ NEW QUESTION ------FROM Malik Ben Achour\n",
      "Adding paragraph...\n",
      "------------------\n",
      "Found 2 questions Malik Ben Achour\n",
      "------ NEW QUESTION ------FROM Malik Ben Achour\n",
      "Adding paragraph...\n",
      "------------------\n",
      "Found 2 questions Malik Ben Achour\n",
      "------ NEW QUESTION ------FROM Malik Ben Achour\n",
      "Adding paragraph...\n",
      "------------------\n",
      "Found 2 questions Malik Ben Achour\n",
      "------ NEW QUESTION ------FROM Marijke Dillen\n",
      "Adding paragraph...\n",
      "------------------\n",
      "Found 3 questions Marijke Dillen\n",
      "Found 3 questions Nawal Farih\n",
      "Found 3 questions Chanelle Bonaventure\n",
      "------ NEW QUESTION ------FROM Marijke Dillen\n",
      "Adding paragraph...\n",
      "------------------\n",
      "Found 3 questions Marijke Dillen\n",
      "Found 3 questions Nawal Farih\n",
      "Found 3 questions Chanelle Bonaventure\n",
      "------ NEW QUESTION ------FROM Kathleen Depoorter\n",
      "Adding paragraph...\n",
      "------------------\n",
      "Found 4 questions Kathleen Depoorter\n",
      "------ NEW QUESTION ------FROM Kathleen Depoorter\n",
      "Adding paragraph...\n",
      "------------------\n",
      "Found 4 questions Kathleen Depoorter\n",
      "------ NEW QUESTION ------FROM Séverine\n",
      "Adding paragraph...\n",
      "------------------\n",
      "Found 5 questions Séverine\n",
      "Found 5 questions Séverine de Laveleye\n",
      "------ NEW QUESTION ------FROM Cécile Cornet\n",
      "Adding paragraph...\n",
      "------------------\n",
      "Found 6 questions Cécile Cornet\n",
      "------ NEW QUESTION ------FROM Cécile Cornet\n",
      "Adding paragraph...\n",
      "------------------\n",
      "Found 6 questions Cécile Cornet\n",
      "Found 6 questions Els\n",
      "Van Hoof\n",
      "Found 6 questions Els Van Hoof\n",
      "Found 6 questions Els\n",
      "Van Hoof\n",
      "Found 6 questions Els Van Hoof\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\u02ba' in position 5789: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 109\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[39m# for next_h2_tag in h2_tag.find_next_siblings(\"h2\"):\u001b[39;00m\n\u001b[0;32m     94\u001b[0m             \u001b[39m#     next_text = next_h2_tag.text.strip()\u001b[39;00m\n\u001b[0;32m     95\u001b[0m             \u001b[39m#     if question_code in next_text:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m                     \u001b[39m# break\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39moutput_1.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m--> 109\u001b[0m     json\u001b[39m.\u001b[39;49mdump (questions, f, ensure_ascii\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    111\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m questions:\n\u001b[0;32m    112\u001b[0m     \u001b[39mprint\u001b[39m(i)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1264.0_x64__qbz5n2kfra8p0\\Lib\\json\\__init__.py:180\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[39m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[39m# a debuggability cost\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m--> 180\u001b[0m     fp\u001b[39m.\u001b[39mwrite(chunk)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1264.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py:19\u001b[0m, in \u001b[0;36mIncrementalEncoder.encode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 19\u001b[0m     \u001b[39mreturn\u001b[39;00m codecs\u001b[39m.\u001b[39mcharmap_encode(\u001b[39minput\u001b[39m,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrors,encoding_table)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\u02ba' in position 5789: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "h2_text_history = []\n",
    "\n",
    "for h2_tag in soup.find_all(\"h2\"):\n",
    "    if h2_tag.text in h2_text_history:\n",
    "        continue\n",
    "    h2_text_history.append(h2_tag.text)\n",
    "    questions_fr = []\n",
    "    questions_nl = []\n",
    "    questions_text = []\n",
    "    # Handle joined questions with \"-\"\n",
    "    if \"Questions jointes de\" in h2_tag.text:\n",
    "        # This is multiple question with - in FR\n",
    "        next_tag = h2_tag.next_sibling.next_sibling.tag\n",
    "        while next_tag == 'h2' and next_tag.text[0] == \"-\":\n",
    "            questions_fr.append(next_tag.text)\n",
    "            h2_text_history.append(next_tag.text)\n",
    "    elif \"Samengevoegde vragen van\":\n",
    "        # This is multiple question with - in NL\n",
    "        next_tag = h2_tag.next_sibling.next_sibling.tag\n",
    "        while next_tag == 'h2' and next_tag.text[0] == \"-\":\n",
    "            questions_nl.append(next_tag.text)\n",
    "            h2_text_history.append(next_tag.text)\n",
    "    else:\n",
    "        # single question\n",
    "        pass\n",
    "\n",
    "    text = h2_tag.text.strip()\n",
    "    question_code_flag = 0\n",
    "    \n",
    "    if re.compile(r\"\\(\\d{8}\\w\\)\").search(text) is None:  # verify that the question title text has the document code, example (55036821C)\n",
    "        continue\n",
    "    \n",
    "    if question_code_flag == 2:  # condition to stop if two different question titles have the same document code\n",
    "        question_code_flag = 0\n",
    "        continue\n",
    "   \n",
    "    question_code = text.split()[-1]\n",
    "    question_code_flag = 1\n",
    "    # Sometimes the first question has FR and the second NL and vice versa, this is a check for it.\n",
    "    try:\n",
    "        if h2_tag.span[\"lang\"] == \"FR\":\n",
    "            question_FR = text\n",
    "            start_with = text.split(\"à\")[0]\n",
    "            end_with = text.split(\"à\")[1]\n",
    "            politician_adressed = end_with.split(\"(\")[0].strip()\n",
    "            if \"Question de\" in start_with:\n",
    "                politician_asking = start_with.split(\"de\")[1].strip()\n",
    "            elif \"-\" in start_with:\n",
    "                politician_asking = \" \".join(start_with.split()[1:])\n",
    "        elif h2_tag.span[\"lang\"] == \"NL\":\n",
    "            question_NL = \" \".join(text.split())\n",
    "            start_with = text.split(\"aan\")[0]\n",
    "            end_with = text.split(\"aan\")[1]\n",
    "            politician_adressed = end_with.split(\"(\")[0].strip()\n",
    "            if \"Vraag van\" in start_with:\n",
    "                politician_asking = start_with.split(\"Vraag van\")[1].strip()\n",
    "            elif \"-\" in start_with:\n",
    "                politician_asking = \" \".join(start_with.split()[1:])\n",
    "    except:\n",
    "        print(\"problem with span lang attribute.\")\n",
    "        print(h2_tag.span)\n",
    "\n",
    "    for p_tag in h2_tag.find_next_siblings(\"p\"):\n",
    "        question_text = \"\"\n",
    "        #print(p_tag.text)\n",
    "        #print(politician_asking)\n",
    "        if re.compile(r\"\\d\\d.01\").search(p_tag.text) and politician_asking in p_tag.text :\n",
    "            print('------ NEW QUESTION ------FROM', politician_asking)\n",
    "            \n",
    "            for next_p_tag in p_tag.find_next_siblings('p'):\n",
    "                if re.compile(r\"\\d\\d.01\").search(next_p_tag.text):\n",
    "                    print(\"Adding paragraph...\")\n",
    "                    # questions.append({  \n",
    "                    #     \"fr_text\": question_FR,\n",
    "                    #     \"nl_text\": question_NL,\n",
    "                    #     \"stakeholders\": [politician_asking, politician_adressed],\n",
    "                    #     \"question_text\" : question_text   \n",
    "                    # })\n",
    "                    if question_text not in questions:\n",
    "                        questions.append(question_text)\n",
    "                    print(\"------------------\")\n",
    "                    break\n",
    "                else:\n",
    "                    if question_text ==  '':\n",
    "                        question_text +=p_tag.text\n",
    "                    question_text += next_p_tag.text\n",
    "    \n",
    "    print(f'Found {len(questions)} questions', politician_asking)    \n",
    "                                            \n",
    "\n",
    "\n",
    "            # for next_h2_tag in h2_tag.find_next_siblings(\"h2\"):\n",
    "            #     next_text = next_h2_tag.text.strip()\n",
    "            #     if question_code in next_text:\n",
    "            #         question_code_flag = 2\n",
    "            #         try:\n",
    "            #             if next_h2_tag.span[\"lang\"] == \"FR\":\n",
    "            #                 question_FR = \" \".join(next_text.split())\n",
    "            #             elif next_h2_tag.span[\"lang\"] == \"NL\":\n",
    "            #                 question_NL = \" \".join(next_text.split())\n",
    "            #         except:\n",
    "            #             print(\"problem with span lang attribute.\")\n",
    "            #             print(h2_tag.span)\n",
    "\n",
    "                    # break\n",
    "\n",
    "with open('output_1.txt', 'w') as f:\n",
    "    json.dump (questions, f, ensure_ascii=False)\n",
    "\n",
    "for i in questions:\n",
    "    print(i)\n",
    "    print('_________________________________________')\n",
    "\n",
    "#print(questions)                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
